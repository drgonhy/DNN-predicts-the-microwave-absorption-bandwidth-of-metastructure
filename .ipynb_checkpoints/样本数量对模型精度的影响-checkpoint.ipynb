{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe199793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "\n",
    "# 设置全局随机种子\n",
    "seed = 3            #3\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Load your data from mydata_petals.csv\n",
    "data = pd.read_csv('mydata_petals.csv')\n",
    "\n",
    "# Extract the last column (EAB) as the target variable\n",
    "EAB = data.iloc[:, -1].values\n",
    "\n",
    "# Extract the first 10 columns as input features\n",
    "input = data.iloc[:, :-1].values\n",
    "\n",
    "# Create MinMaxScaler objects for input and EAB\n",
    "scaler_in = MinMaxScaler(feature_range=(-0.5, 0.5))\n",
    "scaler_out = MinMaxScaler(feature_range=(-0.99, 0.99))\n",
    "\n",
    "# Fit and transform input data, and store the transformation matrix ps_in\n",
    "p_scaled = scaler_in.fit_transform(input)\n",
    "p = torch.FloatTensor(p_scaled.T)\n",
    "ps_in = scaler_in.scale_\n",
    "\n",
    "# Fit and transform EAB data, and store the transformation matrix ts_out\n",
    "t_scaled = scaler_out.fit_transform(EAB.reshape(-1, 1))\n",
    "t = torch.FloatTensor(t_scaled)\n",
    "ts_out = scaler_out.scale_\n",
    "\n",
    "print(\"Scaled Data Shapes:\")\n",
    "print(p_scaled.shape)\n",
    "print(t_scaled.shape)\n",
    "\n",
    "# Define the number of samples for training and testing\n",
    "n_train_samples = 720\n",
    "n_test_samples = 480\n",
    "\n",
    "indices = np.random.RandomState(seed=seed).permutation(len(EAB))\n",
    "\n",
    "# Use the shuffled indices to select the specified number of samples for training and testing\n",
    "train_indices = indices[:n_train_samples]\n",
    "test_indices = indices[n_train_samples:n_train_samples + n_test_samples]\n",
    "\n",
    "# Split the data into training and test sets based on the selected indices\n",
    "X_train, y_train = p_scaled[train_indices], t_scaled[train_indices]\n",
    "X_test, y_test = p_scaled[test_indices], t_scaled[test_indices]\n",
    "\n",
    "# Verify the shapes of the training and test sets\n",
    "print(\"Training Set Shapes:\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "print(\"Test Set Shapes:\")\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "# 打印训练数据前五行\n",
    "print(\"First 5 rows of Training Data:\")\n",
    "print(X_train[:5])\n",
    "print(\"First 5 rows of Training Target (y_train):\")\n",
    "print(y_train[:5])\n",
    "\n",
    "print(\"Test Data Shapes:\")\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# 打印测试数据前五行\n",
    "print(\"First 5 rows of Test Data:\")\n",
    "print(X_test[:5])\n",
    "print(\"First 5 rows of Test Target (y_test):\")\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96d2dba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# 设置全局随机种子\n",
    "#seed = 42\n",
    "#random.seed(seed)\n",
    "#np.random.seed(seed)\n",
    "#torch.manual_seed(seed)\n",
    "\n",
    "# Define your DNN architecture\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dims):\n",
    "        super(DNN, self).__init__()\n",
    "        dims = [input_dim] + hidden_dims + [output_dim]\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(1, len(dims)):\n",
    "            self.layers.append(nn.Linear(dims[i - 1], dims[i]))\n",
    "            if i < len(dims) - 1:\n",
    "                self.layers.append(nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# Define the fitness function for GA\n",
    "def fitness_function(weights, dnn, criterion, inputs, targets):\n",
    "    start_idx = 0\n",
    "    for param in dnn.parameters():\n",
    "        param_size = param.numel()\n",
    "        param.data = torch.FloatTensor(weights[start_idx:start_idx+param_size]).view(param.size())\n",
    "        start_idx += param_size\n",
    "\n",
    "    outputs = dnn(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    return loss.item()\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 10\n",
    "output_dim = 1\n",
    "hidden_dims = [12, 10, 6, 3]\n",
    "\n",
    "# Data\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "# Initialize the DNN\n",
    "dnn = DNN(input_dim, output_dim, hidden_dims)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the problem bounds for GA\n",
    "num_weights = sum(p.numel() for p in dnn.parameters())\n",
    "lb = [-1.0] * num_weights\n",
    "ub = [1.0] * num_weights\n",
    "\n",
    "# Initialize GA parameters\n",
    "pop_size = 30\n",
    "max_generations = 20\n",
    "mutation_rate = 0.1\n",
    "crossover_rate = 0.8\n",
    "\n",
    "# Training parameters\n",
    "external_epochs = 300\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Initialize the population\n",
    "population = [np.random.uniform(lb, ub) for _ in range(pop_size)]\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Main GA loop\n",
    "losses = []\n",
    "\n",
    "for generation in range(max_generations):\n",
    "    fitness_scores = [fitness_function(individual, dnn, criterion, X_train, y_train) for individual in population]\n",
    "    best_index = np.argmin(fitness_scores)\n",
    "    best_individual = population[best_index]\n",
    "\n",
    "    # Apply the best individual's weights to the DNN\n",
    "    start_idx = 0\n",
    "    for param in dnn.parameters():\n",
    "        param_size = param.numel()\n",
    "        param.data = torch.FloatTensor(best_individual[start_idx:start_idx+param_size]).view(param.size())\n",
    "        start_idx += param_size\n",
    "\n",
    "    losses.append(fitness_scores[best_index])\n",
    "\n",
    "    # Select the top performers\n",
    "    num_selection = int(pop_size * 0.2)\n",
    "    selected_indices = np.argsort(fitness_scores)[:num_selection]\n",
    "    selected_population = [population[i] for i in selected_indices]\n",
    "\n",
    "    # Crossover\n",
    "    new_population = []\n",
    "    while len(new_population) < pop_size:\n",
    "        parent1 = random.choice(selected_population)\n",
    "        parent2 = random.choice(selected_population)\n",
    "        if random.random() < crossover_rate:\n",
    "            crossover_point = random.randint(0, num_weights)\n",
    "            child = list(parent1[:crossover_point]) + list(parent2[crossover_point:])\n",
    "            new_population.append(child)\n",
    "\n",
    "    # Mutate\n",
    "    for i in range(pop_size):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_individual = np.random.uniform(lb, ub)\n",
    "            new_population[i] = mutated_individual\n",
    "\n",
    "    population = new_population\n",
    "\n",
    "# After GA, continue training with optimized weights\n",
    "best_individual = population[best_index]  # Use the best individual found by GA\n",
    "start_idx = 0\n",
    "for param in dnn.parameters():\n",
    "    param_size = param.numel()\n",
    "    param.data = torch.FloatTensor(best_individual[start_idx:start_idx+param_size]).view(param.size())\n",
    "    start_idx += param_size    \n",
    "# After GA, continue training with optimized weights\n",
    "optimizer = optim.Adam(dnn.parameters(), lr=learning_rate)\n",
    "for epoch in range(external_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = dnn(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "# Calculate and print the training duration\n",
    "training_duration = end_time - start_time\n",
    "print(f\"Training duration: {training_duration:.2f} seconds\")\n",
    "# Plot the loss curve\n",
    "plt.figure()\n",
    "plt.plot(range(1, max_generations + external_epochs + 1), losses, marker='o', linestyle='-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_train = dnn(torch.FloatTensor(X_train))\n",
    "    train_true_values = y_train\n",
    "    r_train = r2_score(train_true_values, predicted_train)\n",
    "    mae_train = mean_absolute_error(train_true_values, predicted_train)   # MAE training set\n",
    "    mse_train = mean_squared_error(train_true_values, predicted_train)    # MSE training set\n",
    "    rmse_train = math.sqrt(mse_train)                               # RMSE training set\n",
    "\n",
    "print(f\"R-squared (r_train) on training set: {r_train:.3f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on training set: {mae_train:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE) on training set: {mse_train:.3f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) on training set: {rmse_train:.3f}\")\n",
    "\n",
    "with torch.no_grad():              # Perform regression analysis on the test set (X_test, y_test)\n",
    "    predicted_test = dnn(torch.FloatTensor(X_test))\n",
    "    test_true_values = y_test\n",
    "    r_test = r2_score(test_true_values, predicted_test)\n",
    "    mae_test = mean_absolute_error(test_true_values, predicted_test)   #MAE test set\n",
    "    mse_test = mean_squared_error(test_true_values, predicted_test)    # MSE test set\n",
    "    rmse_test = math.sqrt(mse_test)                               #RMSE test set\n",
    "    predicted_train = dnn(torch.FloatTensor(X_train))\n",
    "\n",
    "print(f\"R-squared (r_test) on test set: {r_test:.3f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on test set: {mae_test:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE) on test set: {mse_test:.3f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) on test set: {rmse_test:.3f}\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "actual_train = y_train\n",
    "actual_test = y_test  # Replace 'y_test' with your test labels\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Scatter plot of actual values and regression line for training set\n",
    "axes[0].scatter(actual_train, actual_train, color='blue', label='Actual', marker='o', s=10)\n",
    "axes[0].scatter(actual_train, predicted_train, color='red', label='Predicted', marker='x', s=10)\n",
    "axes[0].set_xlim(-1.2, 1.2)\n",
    "axes[0].set_ylim(-1.2, 1.2)\n",
    "correlation_train = np.corrcoef(actual_train, predicted_train, rowvar=False)[0, 1]\n",
    "axes[0].set_title(f'Training Set\\nCorrelation: {correlation_train:.3f}')\n",
    "regression_train = LinearRegression()\n",
    "regression_train.fit(actual_train.reshape(-1, 1), predicted_train)\n",
    "regression_line_train = regression_train.predict(actual_train.reshape(-1, 1))\n",
    "axes[0].plot(actual_train, regression_line_train, color='green', linestyle='--', label='Regression Line')\n",
    "axes[0].legend()\n",
    "\n",
    "# Scatter plot of actual values and regression line for test set\n",
    "axes[1].scatter(actual_test, actual_test, color='blue', label='Actual', marker='o', s=10)\n",
    "axes[1].scatter(actual_test, predicted_test, color='red', label='Predicted', marker='x', s=10)\n",
    "axes[1].set_xlim(-1.2, 1.2)\n",
    "axes[1].set_ylim(-1.2, 1.2)\n",
    "correlation_test = np.corrcoef(actual_test, predicted_test, rowvar=False)[0, 1]\n",
    "axes[1].set_title(f'Test Set\\nCorrelation: {correlation_test:.3f}')\n",
    "regression_test = LinearRegression()\n",
    "regression_test.fit(actual_test.reshape(-1, 1), predicted_test)\n",
    "regression_line_test = regression_test.predict(actual_test.reshape(-1, 1))\n",
    "axes[1].plot(actual_test, regression_line_test, color='green', linestyle='--', label='Regression Line')\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
